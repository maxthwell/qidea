包含以下内容
分别使用PPO算法进行强化学习，玩一个大家都喜闻乐见的游戏：扎金花。
该问题的难度：
-------------------------------------------------------------------------------------------------------------------------------------------
	                         alphago                               扎金花
-------------------------------------------------------------------------------------------------------------------------------------------
参与人数：                         2                                    2~6
-------------------------------------------------------------------------------------------------------------------------------------------
每一步可选动作                   361-nSteps                             15               
-------------------------------------------------------------------------------------------------------------------------------------------
完成一局游戏的步数               >100                                   <20
-------------------------------------------------------------------------------------------------------------------------------------------
信息透明度               可以观测自身与对手的所有状态量           不能观察到其他对手的状态
-------------------------------------------------------------------------------------------------------------------------------------------
马尔科夫过程             是，当前动作只取决于最近8步的状态        否，当前动作不仅取决于当前状态，还取决于历史动作等，但可以转换为MDP
				（打劫的可能性）
--------------------------------------------------------------------------------------------------------------------------------------------
合作博弈                        否                                可能存在，但是会约束各个玩家独立。
----------------------------------------------------------------------------------------------------------------------------------------------------------------
MCTS                     由于围棋可以使用rollout对策略进行提升    不能基于当前局面进行rollout，因为不知道其他玩家手牌。
----------------------------------------------------------------------------------------------------------------------------------------------------------------
策略提升                       MCTS+A3C                               PPO
----------------------------------------------------------------------------------------------------------------------------------------------------------------
难点                     动作空间的宽度与深度                     状态空间的不确定性与信息的不透明
----------------------------------------------------------------------------------------------------------------------------------------------------------------

通过以上对比可以看出，扎金花是一个比围棋更加简单的游戏，其动作空间的宽度与深度不如围棋，难点在于其是一个多人博弈系统，而围棋仅仅是一个二人博弈系统。


扎金花游戏的当前状态有以下属性：
	c1)玩家个数N
	c2所有玩家的历史动作集。
	c3)当前玩家的手牌。
	c4)当前玩家曾经的比牌对象的手牌
	c5)被淘汰的玩家组成的标志向量
	c6)当前桌面上的玩家组成的标志向量
	c7)当前桌面上总共累积的注数
	c8)当前玩家的id
	c9)当前的轮数
	c10)剩余的轮数
	c11)当前允许押注的最小暗注（明注是暗注的两倍）
	c12)所有玩家的id与座次号。(构建一个N*N的矩阵，其每一行每一列都具有one-hot形式)
	以上状态有一部分冗余的信息，如根据c5,c6可以推导出c1，但是这没关系，因为我们会使用神经网络模型去除冗余信息,保留有用的特征。
	以上信息需要通过一些特殊的数据处理手段进行参数化与张量化，并且将参数限制在（-1，1）之间。如当前的轮数用一个20维的one-hot向量标识，向量的第几个维度为1就代表第几轮。

可以使用的动作：
	无操作(用于看牌阶段选择不看牌)
	看牌（在下注、弃牌，动作之前进行选择是否看牌）
	弃牌
	比牌0	(与第0个玩家比牌)
	比牌1
	比牌2
	比牌3
	比牌4
	比牌5
	下注0
	下注1  (押1,指暗注，明注要下暗注的两倍即要押2)
	下注2  (下2注)
	下注3  (下4注)
	下注4  (下8注)
	下注5  (下16注)
	每一个动作对应一个15维的one-hot向量。

奖励:
	下注就惩罚当前玩家所押的注数。
	比牌就惩罚比牌者当前允许最小注数的两倍。
	游戏结束，把奖励池中的所有注平均给所有的赢家。	

	

游戏结束条件：
	除了一个玩家外，其他的都弃牌或者比牌出局。

玩法：
	s1)发牌
	s2)所有的玩家可以选择执行看牌操作
	s3)玩家1从（下注、比牌、弃牌）中选择一个动作执行，并获取相应的游戏状态，奖励，是否结束等信息。
	s4)重复s2-s3直到桌面上只有一个玩家或者到达最大允许的轮数。
	s5)奖励所有的胜者。

规则:
	r1)前N轮不允许比牌。
	r2)每一个玩家不知道对方的手牌。
	r3)选择看牌后不允许再执行看牌动作
	r4)在看牌阶段如果选择了下注、比牌、弃牌等动作直接被淘汰出局
	r5)下注阶段执行了看牌操作的用户直接out。
	r6)一局游戏结束后，上一局游戏的状态对当前游戏会造成一定影响，需要加入RNN层保留对前面几局的印象。(人经常会受到前面几局游戏的影响，从而影响对当前居面的判断)。

PPO:
	利用PPO进行回合更新，一局游戏代表一个回合。
	每玩一局实际上得到了6个样本，因为可以站在6个不同玩家角度，得到6组轨迹。
	PPO论文链接：https://arxiv.org/pdf/1707.06347.pdf
	
	输出：
		当前玩家采取每一个动作的价值。	
		当前玩家采取每一个动作的概率分布。







